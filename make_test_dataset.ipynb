{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:20:52.114709Z",
     "start_time": "2023-07-25T02:20:52.105946Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:26.139096Z",
     "start_time": "2023-07-25T04:28:26.135007Z"
    }
   },
   "outputs": [],
   "source": [
    "num_col, num_row = 100, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:26.369131Z",
     "start_time": "2023-07-25T04:28:26.354325Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=num_row,\n",
    "    n_features=num_col,\n",
    "    n_informative=1,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=720,\n",
    "    weights=(0.9,0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:26.762471Z",
     "start_time": "2023-07-25T04:28:26.756295Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list()\n",
    "for i in range(1, num_col+1):\n",
    "    cols.append(f'column{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:27.200364Z",
     "start_time": "2023-07-25T04:28:27.194222Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(data=X, columns=cols)\n",
    "res_df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:27.749291Z",
     "start_time": "2023-07-25T04:28:27.741668Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:28.152939Z",
     "start_time": "2023-07-25T04:28:28.147549Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_offsets_in_month(year, month, num_offsets):\n",
    "    # Calculate the number of days in the specified month\n",
    "    days_in_month = (datetime(year, month % 12 + 1, 1) - timedelta(days=1)).day\n",
    "\n",
    "    # Set the start and end datetime for the specified month\n",
    "    start_datetime = datetime(year, month, 1, 0, 0, 0)\n",
    "    end_datetime = datetime(year, month, days_in_month, 23, 59, 59)\n",
    "\n",
    "    # Calculate the time difference in seconds\n",
    "    time_diff_seconds = (end_datetime - start_datetime).total_seconds()\n",
    "\n",
    "    # Generate num_offsets random offsets in seconds within the range\n",
    "    random_offsets = [random.randint(0, int(time_diff_seconds)) for _ in range(num_offsets)]\n",
    "\n",
    "    return random_offsets\n",
    "\n",
    "def random_datetimes_in_month(year, month, num_datetimes):\n",
    "    random_offsets = generate_random_offsets_in_month(year, month, num_datetimes)\n",
    "\n",
    "    # Get the start datetime for the specified month\n",
    "    start_datetime = datetime(year, month, 1, 0, 0, 0)\n",
    "\n",
    "    # Generate random datetimes using the precomputed random offsets\n",
    "    random_datetimes = [start_datetime + timedelta(seconds=offset) for offset in random_offsets]\n",
    "\n",
    "    return random_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:28.755627Z",
     "start_time": "2023-07-25T04:28:28.748246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage for January (month=1) of the year 2023 with almost a million random datetimes\n",
    "year = 2023\n",
    "month = 1\n",
    "random_datetimes = random_datetimes_in_month(year, month, num_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:29.308091Z",
     "start_time": "2023-07-25T04:28:29.300270Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df['date_time'] = random_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark AWS Credentials Example\") \\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:29.773481Z",
     "start_time": "2023-07-25T04:28:29.756397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:31.177915Z",
     "start_time": "2023-07-25T04:28:30.525644Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/07/25 13:28:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode('append').parquet(\"s3a://test-ml-storage/ml-test/aizen_de_test_1.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T04:28:43.009280Z",
     "start_time": "2023-07-25T04:28:34.159641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T01:04:31.231763Z",
     "start_time": "2023-07-25T01:04:30.986951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
